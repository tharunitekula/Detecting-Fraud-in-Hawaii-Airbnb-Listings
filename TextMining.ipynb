{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Text Mining"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "airbnb = pd.read_csv(\"listings-2.csv\")"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1733274760530
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TF-IDF Feature Importance"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "text_columns = [\"name\", \"description\", \"neighborhood_overview\", \"host_name\", \"host_about\", \"amenities\"\n",
        "]\n",
        "#Initialize dictionary\n",
        "top_terms_per_column = {}\n",
        "\n",
        "# Loop through each column to apply TF-IDF\n",
        "for col in text_columns:\n",
        "   \n",
        "    vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
        "\n",
        "    tfidf_matrix = vectorizer.fit_transform(airbnb[col].fillna(''))\n",
        "    \n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "    sums = tfidf_matrix.sum(axis=0)\n",
        "    \n",
        "    data = [(term, sums[0, idx]) for idx, term in enumerate(feature_names)]\n",
        "    ranking = pd.DataFrame(data, columns=['term', 'rank']).sort_values('rank', ascending=False)\n",
        "    \n",
        "    top_terms_per_column[col] = ranking.head()\n",
        "\n",
        "for col, top_terms in top_terms_per_column.items():\n",
        "    print(f\"\\nTop terms for column '{col}':\\n\", top_terms)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nTop terms for column 'name':\n          term         rank\n6975    ocean  1425.045058\n3036    beach  1395.925482\n3091  bedroom  1139.954502\n8916     view  1112.242715\n3604    condo  1030.974647\n\nTop terms for column 'description':\n           term         rank\n4922        br  2563.615370\n4471     beach  1194.293806\n12996    ocean  1002.673882\n15043   resort   956.814199\n4548   bedroom   926.362242\n\nTop terms for column 'neighborhood_overview':\n           term         rank\n2016        br  1613.797167\n1670     beach  1024.165479\n7760     miles   772.773418\n12675  waikiki   696.706960\n7160   located   661.812596\n\nTop terms for column 'host_name':\n          term         rank\n2288     maui  1048.838257\n1206   hawaii   809.737802\n2826  rentals   778.481619\n3441   vacasa   758.949933\n2833   resort   547.877894\n\nTop terms for column 'host_about':\n            term         rank\n12137  vacation  1395.155847\n7382       maui   978.541900\n7044       love   872.832162\n5260     hawaii   761.731695\n821       aloha   687.646011\n\nTop terms for column 'amenities':\n        term         rank\n824   dryer  3857.984016\n1099    hot  3563.108083\n398   alarm  3398.291725\n940    free  3126.935727\n1955  u2013  2894.631248\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1733274768516
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The most important terms in each of these columns seem in line with what we would expect from Hawaii vacation rentals. We can seem under host_name, that 'rentals' is ranked third, suggesting that many hosts are large rental companies instead of individual homeowners. Under amenities, 'u2013' stands out as we do not know what that is referring to."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cosine Similarity"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import pandas as pd\n",
        "\n",
        "text_columns = [\"name\", \"description\", \"neighborhood_overview\", \"host_name\", \"host_about\", \"amenities\"]\n",
        "tfidf_matrices = {}\n",
        "similarity_results = {}\n",
        "sample_size = 500 \n",
        "\n",
        "#Map rows to IDs\n",
        "index_to_id = airbnb[\"id\"].to_dict()\n",
        "\n",
        "#TF-IDF matrices for each column\n",
        "for col in text_columns:\n",
        "    vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=1000)\n",
        "    tfidf_matrices[col] = vectorizer.fit_transform(airbnb[col].fillna(''))\n",
        "\n",
        "#Similarity calculations with sampling\n",
        "for col in text_columns:\n",
        "    tfidf_matrix = tfidf_matrices[col]\n",
        "    \n",
        "    \n",
        "    if tfidf_matrix.shape[0] > sample_size:\n",
        "        tfidf_sample = tfidf_matrix[:sample_size]\n",
        "    else:\n",
        "        tfidf_sample = tfidf_matrix\n",
        "    \n",
        "    \n",
        "    nn = NearestNeighbors(n_neighbors=10, metric=\"cosine\").fit(tfidf_sample)\n",
        "    distances, indices = nn.kneighbors(tfidf_sample)\n",
        "\n",
        "    #Exclude self-pairs, replace indices with IDs\n",
        "    similarity_results[col] = [(index_to_id[i], index_to_id[indices[i][j]], 1 - distances[i][j]) \n",
        "                               for i in range(len(distances)) \n",
        "                               for j in range(1, len(indices[i])) \n",
        "                               if i != indices[i][j] and (1 - distances[i][j]) > 0.8]\n",
        "\n",
        "\n",
        "    print(f\"\\nTop similar pairs in column '{col}':\")\n",
        "    for id1, id2, score in similarity_results[col][:10]:\n",
        "        print(f\"Entry {id1} and Entry {id2} have similarity score: {score}\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nTop similar pairs in column 'name':\nEntry 162600 and Entry 1371205 have similarity score: 0.837395166335527\nEntry 162600 and Entry 1371229 have similarity score: 0.837395166335527\nEntry 162600 and Entry 1365551 have similarity score: 0.837395166335527\nEntry 162600 and Entry 1365599 have similarity score: 0.837395166335527\nEntry 162600 and Entry 1339958 have similarity score: 0.837395166335527\nEntry 162600 and Entry 1371261 have similarity score: 0.837395166335527\nEntry 162600 and Entry 1371734 have similarity score: 0.8287365030934828\nEntry 162600 and Entry 1371831 have similarity score: 0.8287365030934828\nEntry 36789 and Entry 222203 have similarity score: 1.0\nEntry 177939 and Entry 760196 have similarity score: 0.9344967608069812\n\nTop similar pairs in column 'description':\nEntry 5387 and Entry 1466642 have similarity score: 0.9536905941320121\nEntry 13688 and Entry 543962 have similarity score: 0.9206445094386414\nEntry 168205 and Entry 547635 have similarity score: 0.8579653471204687\nEntry 222203 and Entry 36789 have similarity score: 1.0\nEntry 262648 and Entry 1381735 have similarity score: 0.8014497034989557\nEntry 278204 and Entry 1232648 have similarity score: 0.9244069416526766\nEntry 283375 and Entry 271025 have similarity score: 1.0\nEntry 304658 and Entry 1145716 have similarity score: 0.8438784106320076\nEntry 342158 and Entry 342159 have similarity score: 1.0\nEntry 421737 and Entry 964107 have similarity score: 0.8401788376198835\n\nTop similar pairs in column 'neighborhood_overview':\nEntry 192610 and Entry 1427711 have similarity score: 0.9994575764994861\nEntry 37099 and Entry 152046 have similarity score: 1.0\nEntry 200441 and Entry 674312 have similarity score: 1.0\nEntry 205599 and Entry 205622 have similarity score: 1.0\nEntry 262648 and Entry 1381735 have similarity score: 0.9458099981330671\nEntry 271025 and Entry 298221 have similarity score: 1.0\nEntry 271025 and Entry 283375 have similarity score: 1.0\nEntry 274810 and Entry 289023 have similarity score: 1.0\nEntry 278204 and Entry 1232648 have similarity score: 1.0\nEntry 283375 and Entry 298221 have similarity score: 1.0\n\nTop similar pairs in column 'host_name':\nEntry 7888 and Entry 1928093 have similarity score: 1.0\nEntry 7896 and Entry 908283 have similarity score: 0.8000634397387184\nEntry 7896 and Entry 883700 have similarity score: 0.8000634397387184\nEntry 81582 and Entry 578790 have similarity score: 1.0\nEntry 81582 and Entry 554205 have similarity score: 1.0\nEntry 83221 and Entry 421737 have similarity score: 0.8042445761431384\nEntry 83221 and Entry 964107 have similarity score: 0.8042445761431384\nEntry 91091 and Entry 365368 have similarity score: 1.0\nEntry 102918 and Entry 91091 have similarity score: 1.0\nEntry 102918 and Entry 365368 have similarity score: 1.0\n\nTop similar pairs in column 'host_about':\nEntry 5480 and Entry 13932 have similarity score: 1.0\nEntry 5480 and Entry 395965 have similarity score: 1.0\nEntry 102918 and Entry 91091 have similarity score: 1.0\nEntry 104447 and Entry 104452 have similarity score: 1.0\nEntry 104447 and Entry 18465 have similarity score: 1.0\nEntry 104452 and Entry 104447 have similarity score: 1.0\nEntry 104452 and Entry 18465 have similarity score: 1.0\nEntry 162600 and Entry 1371163 have similarity score: 1.0\nEntry 162600 and Entry 1371261 have similarity score: 1.0\nEntry 162600 and Entry 1365363 have similarity score: 1.0\n\nTop similar pairs in column 'amenities':\nEntry 91091 and Entry 102918 have similarity score: 0.9605726483104509\nEntry 91091 and Entry 128160 have similarity score: 0.838976806056466\nEntry 102918 and Entry 91091 have similarity score: 0.9605726483104509\nEntry 102918 and Entry 128160 have similarity score: 0.8058981724647027\nEntry 128160 and Entry 91091 have similarity score: 0.838976806056466\nEntry 128160 and Entry 102918 have similarity score: 0.8058981724647027\nEntry 152046 and Entry 37099 have similarity score: 0.8766230213503102\nEntry 162600 and Entry 1371261 have similarity score: 0.9946303127271816\nEntry 162600 and Entry 1371734 have similarity score: 0.984676316468998\nEntry 162600 and Entry 1371646 have similarity score: 0.984676316468998\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1733274774048
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#View listing descriptions for matched IDs example\n",
        "\n",
        "airbnb[airbnb[\"id\"].isin([806017561091754918, 930473613964233211])][[\"id\",\"host_name\",\"listing_url\", \"description\"]]\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "                       id host_name  \\\n23767  806017561091754918    Steven   \n27256  930473613964233211    Joseph   \n\n                                           listing_url  \\\n23767  https://www.airbnb.com/rooms/806017561091754918   \n27256  https://www.airbnb.com/rooms/930473613964233211   \n\n                                             description  \n23767  Take it easy at this unique and tranquil getaway.  \n27256  Take it easy at this unique and tranquil getaway.  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>host_name</th>\n      <th>listing_url</th>\n      <th>description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>23767</th>\n      <td>806017561091754918</td>\n      <td>Steven</td>\n      <td>https://www.airbnb.com/rooms/806017561091754918</td>\n      <td>Take it easy at this unique and tranquil getaway.</td>\n    </tr>\n    <tr>\n      <th>27256</th>\n      <td>930473613964233211</td>\n      <td>Joseph</td>\n      <td>https://www.airbnb.com/rooms/930473613964233211</td>\n      <td>Take it easy at this unique and tranquil getaway.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1733274801972
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The most interesting column here is the description column because this is the column we expect to be the most unique and original per property. However, we have certain properties which had similarity scores of 1.0 and upon random selection of one such paid, we found what appeared to be identical properties listed by two different hosts. The even used the same license ID, which according to AirBnb is unique per host and property. This warrants further exploration."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### N-gram analysis for word combinations"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#N-gram analysis (sentence patterns)\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "#Store top n-grams\n",
        "top_ngrams_per_column = {}\n",
        "\n",
        "#Loop through each text column\n",
        "for col in text_columns:\n",
        "   \n",
        "    vectorizer = CountVectorizer(ngram_range=(2, 3), stop_words='english')\n",
        "    ngram_matrix = vectorizer.fit_transform(airbnb[col].fillna(''))\n",
        "    ngram_counts = ngram_matrix.sum(axis=0)\n",
        "    ngrams = [(ngram, ngram_counts[0, idx]) for ngram, idx in vectorizer.vocabulary_.items()]\n",
        "    sorted_ngrams = sorted(ngrams, key=lambda x: x[1], reverse=True)\n",
        "    \n",
        "    top_ngrams_per_column[col] = sorted_ngrams[:10]\n",
        "\n",
        "#Print the top n-grams for each column\n",
        "for col, ngrams in top_ngrams_per_column.items():\n",
        "    print(f\"\\nTop n-grams for column '{col}':\")\n",
        "    for ngram, count in ngrams:\n",
        "        print(f\"{ngram}: {count}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nTop n-grams for column 'name':\nocean view: 3034\nocean views: 1174\nfree parking: 829\nbeach club: 624\nwaikiki beach: 590\nko olina: 579\nwalk beach: 497\nhonua kai: 489\nmaui resort: 473\nhot tub: 449\n\nTop n-grams for column 'description':\nbr br: 14287\nocean views: 2996\nwaikiki beach: 2842\nocean view: 2839\nliving room: 2707\nwalking distance: 2112\nwasher dryer: 2104\nbedroom bath: 1876\nfully equipped: 1874\nking bed: 1821\n\nTop n-grams for column 'neighborhood_overview':\nbr br: 7603\nmiles br: 6458\nbeach park: 2282\nwalking distance: 2162\nwaikiki beach: 1712\nala moana: 1274\nshopping center: 1213\npark miles: 1194\nmin drive: 1169\nminute drive: 1127\n\nTop n-grams for column 'host_name':\nresort rentals: 728\nvacasa hawaii: 652\nmaui resort: 526\nmaui resort rentals: 526\nmaui condo: 400\ncb island: 391\nisland vacations: 391\ncb island vacations: 391\ncastle resorts: 391\nresorts hotels: 391\n\nTop n-grams for column 'host_about':\nvacation rental: 5512\nvacation rentals: 4479\nreal estate: 3174\nbig island: 2404\nrental management: 2359\nvacation rental management: 2306\nlook forward: 1704\naloha spirit: 1538\nairbnb com: 1449\nmanagement company: 1435\n\nTop n-grams for column 'amenities':\nhot water: 38500\ncoffee maker: 34415\nsmoke alarm: 32348\nparking premises: 31094\nhair dryer: 30692\ndishes silverware: 27474\nbed linens: 25564\nfree parking: 25191\nkitchen refrigerator: 24625\nalarm dishes: 24587\n"
        }
      ],
      "execution_count": 28,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731537994340
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This analyis is typically used to detect word combinations in spam. In our case, the word combinations are in line with what we would expect for each text column, like 'coffee' and 'maker' under amenities. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}